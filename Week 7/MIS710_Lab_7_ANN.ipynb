{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thuc-github/MIS710-T12023/blob/main/Week%207/MIS710_Lab_7_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNkJtLWoPpW7"
      },
      "source": [
        "\n",
        "# **MIS710 Lecture 7: Introduction to Artificial Neural Networks**\n",
        "\n",
        "Author: Associate Professor Lemai Nguyen\n",
        "\n",
        "Objectives:\n",
        "\n",
        "* To learn to build and test ANN models for classification and regression\n",
        "* To evaluate the models based on the ML problem\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxTV1VTuj9mC"
      },
      "source": [
        "**Loading basic Libraries**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9_TVAw2FOsS"
      },
      "source": [
        "!pip install pydotplus #interface for graph visualisation\n",
        "!pip install graphviz #for graph visualisation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVf5buwkml_I"
      },
      "source": [
        "# load libraries\n",
        "import pandas as pd #for data manipulation and analysis\n",
        "import numpy as np\n",
        " \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Case One: Biopsy**\n",
        "\n",
        "**Cancer Diagnosis**\n",
        "Predict the diagnosis (healthy or cancerous) based on a biopsy dataset.\n",
        "\n",
        "**Context**: The dataset was adapted from a biospy dataset. The dataset contains five (5) biological variables and the target variable. \n",
        "\n",
        "**Approaches**: ANN using schikit learn MLP Classifier and Keras\n",
        "\n",
        "**Dataset**: \n",
        "V1, V2, V7-V9: biological variables\n",
        "Diagnosis: healthy or cancerous\n",
        "\n",
        "**Source**: adapted from a dataset provided by Dr Mark Griffin, Industry Fellow, University of Queensland; https://www.kaggle.com/datasets/ukveteran/biopsy-data-on-breast-cancer-patients \n"
      ],
      "metadata": {
        "id": "-hYSwK4MBEXI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B38Q50gZm1vQ"
      },
      "source": [
        "## **1.1 Loading Data**\n",
        "\n",
        "\n",
        "1.   Load the dataset\n",
        "2.   Explore the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXYXIiopFSPX"
      },
      "source": [
        "# load dataset\n",
        "records = pd.read_csv('https://raw.githubusercontent.com/VanLan0/MIS710/main/biopsy_ln.csv')\n",
        "print(records)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.2 Inspecting and cleansing data**"
      ],
      "metadata": {
        "id": "1kgPiugeC5nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print a sample of 10 datapoints; hint: use the function sample()\n"
      ],
      "metadata": {
        "id": "Rm5pOPRG5hlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#display variables and data types\n"
      ],
      "metadata": {
        "id": "qaThdphidKgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect missing data\n"
      ],
      "metadata": {
        "id": "ytxVLaTRdqaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Sample size:', records.shape[0])\n",
        "print('Number of columns:', records.shape[1]) "
      ],
      "metadata": {
        "id": "QRhrC2p-vLHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop an irrelevant variable(s), then display the remaining variables abd data types\n",
        "\n",
        "records.info()"
      ],
      "metadata": {
        "id": "wRUf0J7ZaFx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.3 EDA**\n",
        "1. Explore descriptive stats and histograms of continuous variables\n",
        "2. Explore descriptive stats and barcharts of categorical variables\n",
        "3. Explore relationships among the variables using heatmaps\n",
        "4. Explore logistric regression relationships between variables \n",
        "\n",
        "Convert data as needed for the exploration tasks"
      ],
      "metadata": {
        "id": "RJhziPbjRRem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**univariable analyses**"
      ],
      "metadata": {
        "id": "0NWu_tqpwzlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#generate descriptive stats for numerical variables\n"
      ],
      "metadata": {
        "id": "w1OFeG-20rL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a stats for each variable and display it histograms for \n",
        "for i in records.iloc[:,:]: \n",
        "    print('Exploring :', i, '\\n', records[i].describe())\n",
        "    plt.hist(records[i])\n",
        "    plt.title(i)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "owNEshpvAb1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create barchats for disgnosis\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VEcOor4L84Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create frequency stats for diagnosis\n"
      ],
      "metadata": {
        "id": "LMhWCwXc95r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**multi-variable analyses**"
      ],
      "metadata": {
        "id": "7KjQJRcDwuNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# complete the for loop below to generate the following boxplots - hint: data=records, x=i, y='diagnosis'\n",
        "for i in records.columns[1:5]:\n",
        "  \n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "8HHwvXQLu3gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate a heatmap"
      ],
      "metadata": {
        "id": "EwrpTLYjOIE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.4 Data preparation and feature selection**"
      ],
      "metadata": {
        "id": "o-q_DuqLExFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert categorical data to numerical \n",
        "def coding_diagnosis(x):\n",
        "        if x=='cancerous': return 1\n",
        "        if x=='healthy': return 0\n",
        "       \n",
        "records['diagnosis'] = records['diagnosis'].apply(coding_diagnosis)\n",
        "\n",
        "print(records.sample(10))"
      ],
      "metadata": {
        "id": "oeNvz-YvcYpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate heatmaps to explore relationships\n",
        "sns.heatmap(records.corr(), cbar=0, linewidths=2,vmax=1, vmin=0, square=True, cmap='Blues', annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wWtdCU5J1l41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What can you observe in all the above analyses?"
      ],
      "metadata": {
        "id": "IDG1zi7KE_ZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Save file for future analyses**"
      ],
      "metadata": {
        "id": "qFe8ZT95O9Yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cOgMN48MPSEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io"
      ],
      "metadata": {
        "id": "GD21DuPJPT0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # save the DataFrame to a CSV file\n",
        "    records.to_csv('/content/drive/My Drive/Colab Notebooks/MIS710/biopsy_processed.csv', index=False)\n",
        "    print('File saved successfully!')\n",
        "except Exception as e:\n",
        "    print(f'An error occurred: {e}')\n",
        "File saved successfully!"
      ],
      "metadata": {
        "id": "MTUeBU39O_Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZn9TsB0IlVZ"
      },
      "source": [
        "### **Feature Selection**\n",
        "\n",
        "* Select predictors (attributes) for Classification\n",
        "* Set role (Target)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eklK57M5Iuba"
      },
      "source": [
        "#Selecting predictors\n",
        "features =['V1', 'V2', 'V7', 'V8', 'V9'] \n",
        "\n",
        "#complete the code below\n",
        "X= records[features]\n",
        "y= records['diagnosis']  # Target variable\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZZL19jGNYpv"
      },
      "source": [
        "## **1.5 Split the dataset**\n",
        "\n",
        "Split arrays or matrices into random train and test subsets\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn.model_selection.train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "BcDVgvyvFCGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WQVc9ZINezn"
      },
      "source": [
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=2023)  # 80% training and 20% testing \n",
        "\n",
        "#inspect the split datasets\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#how many cancer cases are in the training and test sets\n",
        "print((y_train==1).sum())\n",
        "print((y_test==1).sum())"
      ],
      "metadata": {
        "id": "zGQ0HEwnFsRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalise data**"
      ],
      "metadata": {
        "id": "kapFagnShSXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "pfUexlnJE5VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize data\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# The following line of code normalises X_train\n",
        "X_train_norm = scaler.fit_transform(X_train)\n",
        "\n",
        "#Write your own code to normalise X_test"
      ],
      "metadata": {
        "id": "ZcMmoxbzhU4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.5 Initialise and Train a MLPClassifier for the classification problem**\n",
        "\n",
        "Read about the MLP classifiers at:\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html \n"
      ],
      "metadata": {
        "id": "DEhDWoQDhCAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import classes and functions\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "Olzi4LsvhFpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task: Train a neural network**"
      ],
      "metadata": {
        "id": "8wY6t9fohgAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create an MLP classifier with 2 hidden layers - you can change the layers and sizes\n",
        "ann_clf = MLPClassifier(hidden_layer_sizes=(32, 16), max_iter=1000, random_state=2023, early_stopping=True)\n"
      ],
      "metadata": {
        "id": "xPaIx5PhhlkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# complethe the code to fit the model with the training data, note you should use X_train_norm\n"
      ],
      "metadata": {
        "id": "4pUVaWTJyo1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.6 Model evaluation**"
      ],
      "metadata": {
        "id": "MqoO09v3iATB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task: follow the instructions below**"
      ],
      "metadata": {
        "id": "X7X4kFpT0d3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use the classifier on the testing data to make predictions - think carefully which X you should use\n"
      ],
      "metadata": {
        "id": "V6R-r_iLiIAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get predicted probabilities for the main class\n",
        "y_pred_probs = ann_clf.predict_proba(X_test_norm)\n",
        "y_pred_probs = y_pred_probs[:, 1]"
      ],
      "metadata": {
        "id": "Ju8etkodzQSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task: Run and interpret the results below**"
      ],
      "metadata": {
        "id": "PCEXEkQPzXw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print confusion matrix and evaluation report\n",
        "cm=confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "Na-46wR3Fj5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display confusion matrix\n",
        "df_cm = pd.DataFrame(cm, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive'])\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.title('Confusion Matrix')\n",
        "sns.heatmap(df_cm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ukVi25IEi3nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task: Interpret the outcomes below**"
      ],
      "metadata": {
        "id": "pWgPby900Qa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import classes to display RocCurve and Confusion Matrix, read example from the website and try on your own\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "fpr_mlp, tpr_mlp, thresholds = roc_curve(y_test, y_pred_probs)\n",
        "auc_mlp=metrics.auc(fpr_mlp, tpr_mlp)\n",
        "print('AUC:', '%.3f' % auc_mlp)\n",
        "\n",
        "#RocCurveDisplay.from_estimator(logreg,X_test, y_test)\n",
        "RocCurveDisplay.from_predictions(y_test, y_pred_probs)\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Yw2pwSYVjVpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inspection=pd.DataFrame({'Actual':y_test, 'Predicted':y_pred, f'Probability: %5.3f':y_pred_probs})\n",
        "inspection=pd.concat([X_test,inspection], axis=1)\n",
        "inspection.sample(10)"
      ],
      "metadata": {
        "id": "2HEMoFLxiYRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.7 A brief Intro to Keras**\n",
        "scikit-learn's MLP and Keras are popular libraries for building and training artificial neural networks (ANNs) in Python. \n",
        "\n",
        "Scikit-learn's MLP has a simpler and more straightforward API compared to Keras. Keras has a more complex and flexible API, which allows you to build models using a variety of functional and sequential APIs.\n",
        "\n",
        "Scikit-learn's MLP supports only fully connected feedforward neural networks. Keras supports a wider range of architectures including convolutional neural networks (CNNs), recurrent neural networks (RNNs), and more. Keras is built on top of TensorFlow, which allows you to use GPUs and TPUs for faster computation, especially when working with large datasets or complex models. \n",
        "\n",
        "Scikit-learn's MLP is designed to be easy to use, especially for beginners who are new to deep learning. Keras, on the other hand, requires more expertise and knowledge of deep learning concepts, but it provides more flexibility and control over the model."
      ],
      "metadata": {
        "id": "YkBEHRcWnh5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "0XPd-t7qiJ-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHoyywSyLD5h"
      },
      "source": [
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=2023)  # 80% training and 20% testing \n",
        "\n",
        "#inspect the split datasets\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize data\n",
        "scaler = StandardScaler()\n",
        "X_train_norm = scaler.fit_transform(X_train)\n",
        "X_test_norm = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "8nUCmGE3ns-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the ANN model structure\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_shape=(X_train_norm.shape[1],)))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "T5DctZLnn1-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "early_stopping = EarlyStopping(patience=5, monitor='val_loss')\n",
        "model.fit(X_train_norm, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "id": "C4DSKBcMn2pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict test data labels\n",
        "y_pred_probs = model.predict(X_test_norm)\n",
        "y_pred = (y_pred_probs > 0.5)"
      ],
      "metadata": {
        "id": "hfjSFfH0n8EC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print confusion matrix and evaluation report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cm_keras=confusion_matrix(y_test, y_pred)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "23cVbzzuoDGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display confusion matrix\n",
        "df_cm = pd.DataFrame(cm_keras, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive'])\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.title('Confusion Matrix')\n",
        "sns.heatmap(df_cm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cGW7smbIn_WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate AUC for the keras model\n",
        "fpr_keras, tpr_keras, thresholds = roc_curve(y_test, y_pred_probs_keras)\n",
        "auc_keras=metrics.auc(fpr_keras, tpr_keras)\n",
        "print('AUC:', '%.3f' % auc_keras)\n",
        "\n",
        "#RocCurveDisplay.from_estimator(logreg,X_test, y_test)\n",
        "RocCurveDisplay.from_predictions(y_test, y_pred_probs_keras)\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_keras)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "goX-SEAQoI0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.8 Model comparison**"
      ],
      "metadata": {
        "id": "OjCdijXSP_J2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate performance metrics for ann_clf\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred)\n",
        "precision_mlp = precision_score(y_test, y_pred)\n",
        "recall_mlp = recall_score(y_test, y_pred)\n",
        "f1_mlp = f1_score(y_test, y_pred)\n",
        "\n",
        "print('MLP Accuracy: ','%.2f' % accuracy_mlp)\n",
        "print('MLP Precision: ', '%.2f' % precision_mlp)\n",
        "print('MLP Recall: ',  '%.2f' % recall_mlp)\n",
        "print('MLP F1 :',  '%.2f' % f1_mlp)"
      ],
      "metadata": {
        "id": "nNZepI7gQE_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your own code to calculate performance metrics for the keras mlp and print them out"
      ],
      "metadata": {
        "id": "NK9llONnQXv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#write our code to get fpr_mlp, tpr_mlp and fpr_keras, tpr_keras"
      ],
      "metadata": {
        "id": "2Yq-mBxAQqRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC curves\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_mlp, tpr_mlp, color='darkorange', lw=2, label='scikit-learn MLP (AUC = %0.2f)' % auc_mlp)\n",
        "plt.plot(fpr_keras, tpr_keras, color='navy', lw=2, label='Keras MLP (AUC = %0.2f)' % auc_keras)\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Compute and print AUC\n",
        "print('scikit-learn MLP AUC:','%.2f' %  auc_mlp)\n",
        "print('Keras MLP AUC:', '%.2f' %auc_keras)"
      ],
      "metadata": {
        "id": "_XZPFtHlQpQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Case Two: Health insurance**\n",
        "\n",
        "**MLP regression**\n",
        "\n",
        "https://www.kaggle.com/datasets/mirichoi0218/insurance \n",
        "\n",
        "**Context**\n",
        "Machine Learning with R by Brett Lantz is a book that provides an introduction to machine learning using R. As far as I can tell, Packt Publishing does not make its datasets available online unless you buy the book and create a user account which can be a problem if you are checking the book out from the library or borrowing the book from a friend. All of these datasets are in the public domain but simply needed some cleaning up and recoding to match the format in the book.\n",
        "\n",
        "Content - Columns\n",
        "\n",
        "* age: age of primary beneficiary\n",
        "\n",
        "* sex: insurance contractor gender, female, male\n",
        "\n",
        "* bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n",
        "objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
        "\n",
        "* children: Number of children covered by health insurance / Number of dependents\n",
        "\n",
        "* smoker: Smoking\n",
        "\n",
        "* region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
        "\n",
        "* charges: Individual medical costs billed by health insurance\n",
        "\n",
        "**Acknowledgements**\n",
        "The dataset is available on GitHub here.\n",
        "\n",
        "**Inspiration**\n",
        "Can you accurately predict insurance costs?\n",
        "\n"
      ],
      "metadata": {
        "id": "-tquMENACBcA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using ANN for regression problems**\n",
        "\n",
        "Read about MLP regressors at:\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor\n",
        "\n",
        "Train Test Split:\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn.model_selection.train_test_split"
      ],
      "metadata": {
        "id": "e2wju-8wynqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.1 Loadding data**"
      ],
      "metadata": {
        "id": "BU71teG1dpmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url='https://raw.githubusercontent.com/VanLan0/MIS710/main/insurance.csv'"
      ],
      "metadata": {
        "id": "krhPWsq5yr9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading data\n",
        "records = pd.read_csv(url)\n",
        "records.head()"
      ],
      "metadata": {
        "id": "u--5Oupwyugh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.2 Cleansing and preprocessing data**"
      ],
      "metadata": {
        "id": "08pat59qduSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect missing data\n"
      ],
      "metadata": {
        "id": "n-z9fRtX7Ir9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert categorical variables to numerical using get dummies\n",
        "\n",
        "print(records.info())\n"
      ],
      "metadata": {
        "id": "IlysE2Vd7YBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records=records.rename(columns={'smoker_yes': 'smoker'})"
      ],
      "metadata": {
        "id": "irt4C8V4cvC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.3 EDA - Do it yourself**"
      ],
      "metadata": {
        "id": "RZ5FNa9Nd2XS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.4 Data Preparation Splitting**"
      ],
      "metadata": {
        "id": "Q-L013KUh-9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Save file for future analyses**"
      ],
      "metadata": {
        "id": "K_qzZwoISGIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do it yourself\n",
        "* mount google drive\n",
        "* import io\n",
        "* save the records data frame to Insurance_processed.csv"
      ],
      "metadata": {
        "id": "NmC36ntfSLQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feature selection**"
      ],
      "metadata": {
        "id": "oYHod5vcPoB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=records.drop('charges', axis=1)\n",
        "y=records['charges']"
      ],
      "metadata": {
        "id": "pqWAXVcw7o9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load libraries**"
      ],
      "metadata": {
        "id": "eIIG9BPs-CcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n"
      ],
      "metadata": {
        "id": "2dnVcVK_-EXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets, use test_size=0.2, random_state=2023)"
      ],
      "metadata": {
        "id": "Pg7SzqrP-R1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the X_train and X_norm data using StandardScaler\n",
        "scaler = StandardScaler()\n"
      ],
      "metadata": {
        "id": "UNB6OSmC7rlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.5 Initialise and Train a MLPRegressor for the regression problem**"
      ],
      "metadata": {
        "id": "BYHIaVU4iGDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an ANN model and fit it to the scaled training data\n",
        "model = MLPRegressor(hidden_layer_sizes=(32,16), activation='relu', solver='adam', max_iter=1000, random_state=2023)\n",
        "\n",
        "#fit the model yourself\n",
        "model.fit(X_train_norm, y_train)"
      ],
      "metadata": {
        "id": "SUShoVPY-mI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.6 Model Evaluation**"
      ],
      "metadata": {
        "id": "ewhMo-dEiQtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained model to predict on the normalised test data, hint: y_pred_mlp = \n",
        "\n"
      ],
      "metadata": {
        "id": "cj_T8SQe-p5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate RMSE, R-squared, and MAE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred_mlp))\n",
        "r2 = r2_score(y_test, y_pred_mlp)\n",
        "mae = mean_absolute_error(y_test, y_pred_mlp)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"RMSE: {:.3f}\" .format(rmse))\n",
        "print(\"R-squared: {:.3f}\" .format(r2))\n",
        "print(\"MAE: {:.3f}\" .format(mae))"
      ],
      "metadata": {
        "id": "-XU3evKclMt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records.charges.describe()"
      ],
      "metadata": {
        "id": "HuT56Ibtep1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot residuals, i.e. the differences between the actual and predicted values. \n",
        "plt.hist(x=y_test-y_pred_mlp, bins=50)\n",
        "plt.xlabel='error'\n",
        "plt.ylabels='count'\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MVLGob6UevCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from importlib import reload\n",
        "plt=reload(plt)"
      ],
      "metadata": {
        "id": "CVPfLmpSfCqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a scatter plot of residuals against predicted values\n",
        "plt.scatter(y_pred, y_test-y_pred_mlp)\n",
        "plt.title('Residual Plot')\n",
        "plt.ylabel('Residuals')\n",
        "plt.xlabel('Predicted values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BZuLrycRe7Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.7 A Brief Intro to Keras (cont)**"
      ],
      "metadata": {
        "id": "ujUhdCSriY5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import History"
      ],
      "metadata": {
        "id": "HNDYo7_Winhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_norm.shape"
      ],
      "metadata": {
        "id": "YyWj_mxLi0B3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=6, activation='relu', input_shape=(X_train_norm.shape[1],)))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# compile the keras model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "history = History()\n",
        "history=model.fit(X_train_norm, y_train, epochs=100, batch_size=32, verbose=0, callbacks=[history])\n",
        "\n"
      ],
      "metadata": {
        "id": "Q9N5u4H0j2Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions using the model\n",
        "y_pred_keras = model.predict(X_test_norm)\n",
        "\n",
        "# calculate evaluation metrics\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred_keras))\n",
        "mae = mean_absolute_error(y_test, y_pred_keras)\n",
        "r2 = r2_score(y_test, y_pred_keras)\n",
        "\n",
        "print('RMSE: {:.2f}'.format(rmse))\n",
        "print('MAE: {:.2f}'.format(mae))\n",
        "print('R-squared: {:.2f}'.format(r2))\n"
      ],
      "metadata": {
        "id": "pXjpp0R5kKIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the loss and accuracy over epochs\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['mean_squared_error'])\n",
        "plt.title('Model Mean Squared Error')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MpjcwJ81kuF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the residuals\n",
        "residuals = y_test - y_pred_keras.squeeze()\n"
      ],
      "metadata": {
        "id": "tDzy2L9vrnNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot residuals, i.e. the differences between the actual and predicted values. \n",
        "plt.hist(residuals, bins=50)\n",
        "plt.xlabel='error'\n",
        "plt.ylabels='count'\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PM0pfMIsrZrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a scatter plot of residuals against predicted values\n",
        "plt.scatter(y_pred_keras, residuals)\n",
        "plt.title('Residual Plot')\n",
        "plt.ylabel('Residuals')\n",
        "plt.xlabel('Predicted values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UG8l5ITXtedA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.8 Model Comparison**"
      ],
      "metadata": {
        "id": "X_oDobxnSd1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the above two MPLRegressor and keras models "
      ],
      "metadata": {
        "id": "yiWD85zC2CVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the regression line for y_test and y_pred_mlp\n",
        "slope_mlp, intercept_mlp = np.polyfit(y_test, y_pred_mlp, 1)\n",
        "regression_line_mlp = slope_mlp * y_test + intercept_mlp"
      ],
      "metadata": {
        "id": "QCgmovu3SyH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#write your code to calculate the regression line for y_test and y_pred_keras"
      ],
      "metadata": {
        "id": "V6YaV1GrSy_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a scatter plot of true against predicted values for MLP and Keras\n",
        "plt.scatter(y_test, y_pred_mlp)\n",
        "plt.plot(y_test, regression_line_mlp, color='blue')\n",
        "plt.scatter(y_test, y_pred_keras, marker='D', s=10, color='orange')\n",
        "plt.plot(y_test, regression_line_keras, color='orange')\n",
        "plt.title('true against predicted values for keras')\n",
        "plt.ylabel('Predicted values')\n",
        "plt.xlabel('True values')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p2YTIu-5S8of"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}