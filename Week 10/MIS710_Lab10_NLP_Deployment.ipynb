{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thuc-github/MIS710-T12023/blob/main/Week%2010/MIS710_Lab10_NLP_Deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNkJtLWoPpW7"
      },
      "source": [
        "\n",
        "# **MIS710 Lab 10 Week 10 Deployment Solution**\n",
        "Author: Associate Professor Lemai Nguyen\n",
        "\n",
        "Objectives: \n",
        "1. To learn text analytics and NLP basics\n",
        "2. To apply the basic skills on the well-known Internet Movie Database developed by Stanford researcher Andrew Maas.\n",
        "3. To apply the basic skills on another review dataset.\n",
        "4. To learn basic MLOps: saving your model and loading and using it later.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSX6_DT9CA72"
      },
      "source": [
        "# **1. Import libraries and functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVf5buwkml_I"
      },
      "outputs": [],
      "source": [
        "# import libraries \n",
        "import pandas as pd #for data manipulation and analysis\n",
        "import numpy as np\n",
        " \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNs6sdotgQHz"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics \n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B38Q50gZm1vQ"
      },
      "source": [
        "# **2. Case One: IMDb**\n",
        "\n",
        "**Sentiment analysis**\n",
        "\n",
        "**Context**\n",
        "IMDb stands for the Internet Movie Database, which is an online database of information related to films, television programs, and video games. It contains a vast collection of data on various aspects of the entertainment industry, including cast and crew information, production details, plot summaries, and user ratings and reviews.\n",
        "\n",
        "**Content**\n",
        "The IMDb dataset has been widely used in sentiment analysis research. The dataset contains 50,000 movie reviews. Each review is labeled as either \"positive\" or \"negative\" based on the overall sentiment expressed in the review. \n",
        "\n",
        "The dataset consists of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well. Raw text and already processed bag of words formats are provided. \n",
        "\n",
        "**Inspiration**\n",
        "To train and test a sentiment analysis model\n",
        "\n",
        "**Further information**:\n",
        "Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011). \n",
        "\n",
        "http://ai.stanford.edu/~amaas/data/sentiment/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAIPvEeNyJYr"
      },
      "source": [
        "## **3. ML Operationalisation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoMhKJ882Fp8"
      },
      "source": [
        "### **3.2 Load and use the model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k27eUV638vMr",
        "outputId": "27851c5b-727a-4609-f065-e73a21a417fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZlJI4aqzMqb"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#modify the code below to point to your picked model\n",
        "#or use my models from here https://github.com/VanLan0/MIS710-ML/tree/main/Pickled\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/MIS710/IMDB_ann_clf.pickle'"
      ],
      "metadata": {
        "id": "G3Z1iQ8IjWI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxRjDs-S2HfC"
      },
      "outputs": [],
      "source": [
        "with open(path, 'rb') as f:\n",
        "    model = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcDkrlYzBe0_"
      },
      "outputs": [],
      "source": [
        "# Load the vocabulary used to preprocess the training data\n",
        "#Modify the code below to point to your vocabulary \n",
        "#or use my pickled vocabulay from here https://github.com/VanLan0/MIS710-ML/tree/main/Pickled\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/MIS710/IMDB_vocabulary.pkl', 'rb') as file:\n",
        "    vocabulary = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the size of the vocabulary\n",
        "print(\"Size of vocabulary:\", len(vocabulary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg13YT7GO4E1",
        "outputId": "da13f447-bad1-4280-c587-8894f452e6d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary: 156040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load new reviews from the 'production line'.\n",
        "\n"
      ],
      "metadata": {
        "id": "OGEIZa7DSptk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvC7NfDQ8AH7",
        "outputId": "6e8451ec-4c46-4a56-c1d9-a20b759231cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               review sentiment\n",
            "0   I just watched the first episode and itâ€™s 10/1...  positive\n",
            "1   this is going to be absolutely hilarious I can...  positive\n",
            "2   Accidentally watched the first episode, it was...  positive\n",
            "3                          This actress is hilarious!  positive\n",
            "4                             Looks very entertaining  positive\n",
            "5                 annoying unnecesarry romantic scene  negative\n",
            "6                           I love this drama so much  positive\n",
            "7   Too convoluted and over dramatic. Dr Cha neede...  negative\n",
            "8   Really good to see Km Byung Chul in a more com...  positive\n",
            "9   disappointed if the writers keep this marriage...  negative\n",
            "10  I'm addicted to this movie, but If she doesn't...  positive\n",
            "11      I love it. Can't wait to see the next episode  positive\n",
            "12  The movie really disappoint me, his mother wil...  negative\n",
            "13  Loved the first 2 episodes and excited for the...  positive\n"
          ]
        }
      ],
      "source": [
        "url='https://raw.githubusercontent.com/VanLan0/MIS710-ML/main/Datasets/DrCha_reviews.csv'\n",
        "new_reviews = pd.read_csv(url)\n",
        "print(new_reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In practice, we should create a data pipeline to automate the pre-process of data. Let's repeat the pre-processing steps for now."
      ],
      "metadata": {
        "id": "ZvyT1DkoZ_GQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzaQV03AS4o3"
      },
      "outputs": [],
      "source": [
        "#import the Python module re to work with regular expressions\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-Ymx5W6S4o3"
      },
      "outputs": [],
      "source": [
        "# Define function to clean text\n",
        "def clean_text(text):\n",
        "  # Remove HTML tags\n",
        "  text = re.sub(r'<.*?>', '', text)\n",
        "  # Remove punctuation and special characters\n",
        "  text = re.sub(r'[^\\w\\s]', '', text)\n",
        "  # Remove extra whitespace\n",
        "  text = re.sub(r'\\s+', ' ', text).strip()\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df9pSxt-S4o5"
      },
      "outputs": [],
      "source": [
        "def lowercasing(text):\n",
        "  # Convert to lowercase\n",
        "  text = text.lower()\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmkltgrZS4o6"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fef16ab5-8533-4884-d7e0-13436adb1e09",
        "id": "2T4HSuV3S4o6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6fQ4unhS4o6"
      },
      "outputs": [],
      "source": [
        "# define stopwords without negation words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "negation_words = {'no', 'not', 'nor', 'neither', 'none', 'never'}\n",
        "filtered_words = [word for word in stop_words if word not in negation_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-ZYlD74S4o6"
      },
      "outputs": [],
      "source": [
        "#define a function to perform tokenization, stemming and lemmatization\n",
        "def tokenize_stem_lemmatize(text):\n",
        "  #tokenization\n",
        "  tokens = nltk.word_tokenize(text.lower())\n",
        "    \n",
        "  #initialize stemmer and lemmatizer  \n",
        "  stemmer = PorterStemmer()\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "  #perform stemming and lemmatization \n",
        "  stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "  lemmatized_tokens = [lemmatizer.lemmatize(token) for token in stemmed_tokens if token not in filtered_words and token.lower() not in negation_words]\n",
        "  return ' '.join(lemmatized_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiPvbJALS4o4"
      },
      "outputs": [],
      "source": [
        "# Write your code to apply the clean_text function to the 'review' column \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqNtAyyxS4o5"
      },
      "outputs": [],
      "source": [
        "# Write your code to apply the lowercasing function to the 'review' column \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoA6_VmpS4o7"
      },
      "outputs": [],
      "source": [
        "# Write yourcode to tokenize, stem, and lemmatize the 'review' column \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFfEr73F9k-d",
        "outputId": "a4465a92-2a45-438b-de7f-a50e8476350c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     watch first episod 1010 im love mom also left ...\n",
              "1         thi go absolut hilari cant wait synopsi funni\n",
              "2     accident watch first episod wa good couldnt st...\n",
              "3                                    thi actress hilari\n",
              "4                                   look veri entertain\n",
              "5                        annoy unnecesarri romant scene\n",
              "6                                   love thi drama much\n",
              "7     convolut dramat dr cha need assert confid fema...\n",
              "8               realli good see km byung chul comed set\n",
              "9         disappoint writer keep thi marriag togeth end\n",
              "10    im addict thi movi doesnt divorc husband watch...\n",
              "11                       love cant wait see next episod\n",
              "12    movi realli disappoint hi mother pain find hi ...\n",
              "13                    love first 2 episod excit remaind\n",
              "Name: review, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "processed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaEBsHxp94rZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Write your code to create a vector representation of the text data using the pickled vocabulary\n",
        "\n",
        "\n",
        "#Write your code to fit the vectorizer with the processed_text, save it in X_vec = \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brFD8A_c-NXI"
      },
      "outputs": [],
      "source": [
        "# Use the model to make predictions on X_vec\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#join unseen y_test with predicted value into a data frame\n",
        "inspection=pd.DataFrame({'Actual':new_reviews['sentiment'], 'Predicted':y_pred})\n",
        "\n",
        "#join X_test with the new dataframe\n",
        "inspection=pd.concat([new_reviews['review'],inspection], axis=1)\n",
        "\n",
        "inspection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "VjURH8pfPcOF",
        "outputId": "f46be8e4-52a0-4fca-ee6d-15ef95ffbfa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               review    Actual Predicted\n",
              "0   i just watched the first episode and its 1010 ...  positive  positive\n",
              "1   this is going to be absolutely hilarious i can...  positive  positive\n",
              "2   accidentally watched the first episode it was ...  positive  positive\n",
              "3                           this actress is hilarious  positive  positive\n",
              "4                             looks very entertaining  positive  positive\n",
              "5                 annoying unnecesarry romantic scene  negative  negative\n",
              "6                           i love this drama so much  positive  positive\n",
              "7   too convoluted and over dramatic dr cha needed...  negative  negative\n",
              "8   really good to see km byung chul in a more com...  positive  positive\n",
              "9   disappointed if the writers keep this marriage...  negative  negative\n",
              "10  im addicted to this movie but if she doesnt di...  positive  negative\n",
              "11        i love it cant wait to see the next episode  positive  positive\n",
              "12  the movie really disappoint me his mother will...  negative  negative\n",
              "13  loved the first 2 episodes and excited for the...  positive  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-717e4879-e401-48b2-8961-6cd7f98ad8f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i just watched the first episode and its 1010 ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this is going to be absolutely hilarious i can...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>accidentally watched the first episode it was ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this actress is hilarious</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>looks very entertaining</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>annoying unnecesarry romantic scene</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>i love this drama so much</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>too convoluted and over dramatic dr cha needed...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>really good to see km byung chul in a more com...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>disappointed if the writers keep this marriage...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>im addicted to this movie but if she doesnt di...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>i love it cant wait to see the next episode</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>the movie really disappoint me his mother will...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>loved the first 2 episodes and excited for the...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-717e4879-e401-48b2-8961-6cd7f98ad8f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-717e4879-e401-48b2-8961-6cd7f98ad8f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-717e4879-e401-48b2-8961-6cd7f98ad8f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print confusion matrix and evaluation report\n",
        "y_test=new_reviews['sentiment']\n",
        "cm=confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cm)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roj9cZS-PS_u",
        "outputId": "4bef98ae-eb50-4fa8-9727-06afdd1cafc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 0]\n",
            " [1 9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.80      1.00      0.89         4\n",
            "    positive       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.90      0.95      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nrv8-AnX3hED"
      },
      "source": [
        "You can test it on a new data set, but make sure you do the same preprocessing first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mtzwlk8yMEu"
      },
      "source": [
        "# **Congratulations**\n",
        "Well done, you have loaded and used your first pre-trained model!\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}