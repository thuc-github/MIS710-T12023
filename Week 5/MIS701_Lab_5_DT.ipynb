{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thuc-github/MIS710-T12023/blob/main/Week%205/MIS701_Lab_5_DT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNkJtLWoPpW7"
      },
      "source": [
        "\n",
        "# **MIS710 Lecture 5**\n",
        "\n",
        "**Introduction to Decision Tree and KNN **\n",
        "Author: Associate Professor Lemai Nguyen\n",
        "\n",
        "Objective:\n",
        "**Predict golf playing**\n",
        "Predict if a play will likely to play golf based on weather conditions.\n",
        "\n",
        "**Context**: To help a golf club needs to predict if a golfer comes to play based on their play history and weather conditions. \n",
        "\n",
        "**Data**: \n",
        "Outlook = The outlook of the weather\n",
        "\n",
        "Temperature = The temperature of the weather\n",
        "\n",
        "Humidity = The humidity of the weather\n",
        "\n",
        "Windy = A variable if it is windy that day or not\n",
        "\n",
        "Play = The label, if the golfer played golf that day or not\n",
        "\n",
        "**Source**: Kotu andÂ Deshpande, 2019, chapter 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxTV1VTuj9mC"
      },
      "source": [
        "**Loading Libraries and Functions**\n",
        "\n",
        "Read about Logistic Regression at:\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "Train Test Split:\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn.model_selection.train_test_split\n",
        "\n",
        "Classification metrics:\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9_TVAw2FOsS"
      },
      "source": [
        "!pip install pydotplus #interface for graph visualisation\n",
        "!pip install graphviz #for graph visualisation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVf5buwkml_I"
      },
      "source": [
        "# load libraries\n",
        "import pandas as pd #for data manipulation and analysis\n",
        "import numpy as np\n",
        " \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.io.parsers.readers import annotations\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeRegressor # Import Decision Tree Regressor\n",
        "\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for model evaluation\n",
        "\n",
        "#print confusion matrix and evaluation report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Biopsy**\n",
        "\n",
        "Let's try another dataset we are familiar with from Week 4"
      ],
      "metadata": {
        "id": "MzWC-EbFV9sM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading data**"
      ],
      "metadata": {
        "id": "03lf4AIsXoBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url='https://raw.githubusercontent.com/VanLan0/MIS710-ML/main/Datasets/biopsy_ln.csv'"
      ],
      "metadata": {
        "id": "cSRAUmkvXrmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "#records = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MIS710/biopsy_ln.csv\")\n",
        "records = pd.read_csv('https://raw.githubusercontent.com/VanLan0/MIS710-ML/main/Datasets/biopsy_ln.csv')\n"
      ],
      "metadata": {
        "id": "q3oiwzyLX4Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Inspecting and preparing data**"
      ],
      "metadata": {
        "id": "kWfqWUzFYGVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#explore the dataset\n",
        "print(records)"
      ],
      "metadata": {
        "id": "PCFgngnrYciK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records.info()"
      ],
      "metadata": {
        "id": "NtvvD4G6YfNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect missing data\n",
        "records.isnull().sum()"
      ],
      "metadata": {
        "id": "FT8xEzM8YFl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop irrelevant variables\n",
        "records=records.drop(['ID'], axis=1)"
      ],
      "metadata": {
        "id": "yDtPnFyxYWg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert categorical data to numerical \n",
        "def coding_diagnosis(x):\n",
        "        if x=='cancerous': return 1\n",
        "        if x=='healthy': return 0\n",
        "       \n",
        "records['Diagnosis'] = records['diagnosis'].apply(coding_diagnosis)\n",
        "\n",
        "print(records.sample(10))"
      ],
      "metadata": {
        "id": "UjO7eTTgYuZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records.info()"
      ],
      "metadata": {
        "id": "m2lVZ2zbYxNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Visually Exploring Data**\n",
        "1. Explore histograms of continuous variables\n",
        "2. Generate barcharts of categorical variables\n",
        "3. Convert data as needed\n",
        "3. Explore relationships among the variables using heatmaps\n",
        "4. Explore logistric regression relationships between variables "
      ],
      "metadata": {
        "id": "RJhziPbjRRem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create histograms\n",
        "for i in records.iloc[:,:6]: \n",
        "    plt.hist(records[i])\n",
        "    plt.title(i)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "owNEshpvAb1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create barchats\n",
        "plot=sns.countplot(data=records, x='diagnosis')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VEcOor4L84Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create barchats\n",
        "plot=sns.countplot(data=records, x='Diagnosis')\n"
      ],
      "metadata": {
        "id": "URB7faEOYGiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(data=records.corr(), cmap=\"Blues\", annot=True)"
      ],
      "metadata": {
        "id": "EwrpTLYjOIE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.regplot(x=records['V2'], y=records['Diagnosis'], logistic=True, ci=None)"
      ],
      "metadata": {
        "id": "3Quobz1KZEXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in records.iloc[:,0:5]: \n",
        "  sns.regplot(x=records[i], y=records['Diagnosis'], logistic=True, ci=None)\n",
        "  plt.title(i)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "zdBy-j02ZUDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZn9TsB0IlVZ"
      },
      "source": [
        "## **Selection Features and Label**\n",
        "\n",
        "Select predictors (attributes) for Classification\n",
        "Set role (Target)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eklK57M5Iuba"
      },
      "source": [
        "#Selecting predictors and label\n",
        "features = records.columns[0:5]\n",
        "X=records[features]  #Input data\n",
        "y=records['Diagnosis'] # Target variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "id": "RRp9GTcpA8ZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "8ln1Vbzs-7o2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZZL19jGNYpv"
      },
      "source": [
        "## **Splitting the Dataset**\n",
        "\n",
        "Split arrays or matrices into random train and test subsets\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn.model_selection.train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WQVc9ZINezn"
      },
      "source": [
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)  # 80% training and 20% testing \n",
        "\n",
        "#inspect the split datasets\n",
        "print(X_train.head())\n",
        "print(y_train.head())\n",
        "\n",
        "print('Training dataset size:',X_train.shape[0])\n",
        "print('Test dataset size:',X_test.shape[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTtxQ1QBNuCM"
      },
      "source": [
        "## **Training and Applying a Decision Tree Classifier**\n",
        "\n",
        "Train a model using the training dataset\n",
        "Make prediction using the model for the test dataset\n",
        "Read about DecisionTreeClassifier at: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j42G9zCxN7xI"
      },
      "source": [
        "# Create Decision Tree classifier object\n",
        "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3) #default criterion is gini, max_depth=25\n",
        "\n",
        "# Train Decision Tree Classifer with the traning dataset \n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "#Make predictions for the test dataset\n",
        "y_pred = clf.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LytoxXxiOIud"
      },
      "source": [
        "**Inspect Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X3Nu4SCOGnI"
      },
      "source": [
        "#join unseen y_test with predicted value into a data frame\n",
        "inspection=pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})\n",
        "\n",
        "#join X_test with the new dataframe\n",
        "inspection=pd.concat([X_test,inspection], axis=1)\n",
        "\n",
        "inspection.sample(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACm74vWIOM7x"
      },
      "source": [
        "## **Evaluating the model**\n",
        "\n",
        "\n",
        "\n",
        "1.   Calculate Accuracy, Precision, Recall, F1\n",
        "\n",
        "\n",
        "Classification metrics: https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Evaluation, calculate metrics: Accuracy, Precision, Recall, F1,\n",
        "print(\"Accuracy: \", '%.3f' % metrics.accuracy_score(y_test,y_pred))\n",
        "print(\"Precision: \",'%.3f' % metrics.precision_score(y_test,y_pred))\n",
        "print(\"Recall: \", '%.3f' % metrics.recall_score(y_test,y_pred))\n",
        "print(\"F1: \", '%.3f' % metrics.f1_score(y_test,y_pred))\n"
      ],
      "metadata": {
        "id": "IY8ojSKAcwvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvYek0KZ-SdW"
      },
      "source": [
        "#print confusion matrix and evaluation report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgbNM-FkRwcL"
      },
      "source": [
        "### **Plot ROC (Receiver operating characteristic) curve and confusion matrix**\n",
        "\n",
        "ROC surve\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_roc_curve.html?highlight=plot_roc_curve#sklearn.metrics.plot_roc_curve\n",
        "\n",
        "Confusion matrix\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html?highlight=plot%20confusion%20matrix#sklearn.metrics.plot_confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get predicted probabilities for the main class\n",
        "y_pred_probs = clf.predict_proba(X_test)\n",
        "y_pred_probs = y_pred_probs[:, 1]\n",
        "y_pred_probs"
      ],
      "metadata": {
        "id": "aDtrvCZxbp6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "RocCurveDisplay.from_predictions(y_test, y_pred_probs)\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QrxcQHBvyazT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Visualising the trees**"
      ],
      "metadata": {
        "id": "wQbx9dRLbl5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydotplus #interface for graph visualisation\n",
        "!pip install graphviz #for graph visualisation"
      ],
      "metadata": {
        "id": "ANQWMhUjbpzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import six\n",
        "import sys\n",
        "sys.modules['sklearn.externals.six'] = six"
      ],
      "metadata": {
        "id": "_F46_pkocDcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries and classes\n",
        "from six import StringIO\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "import pydotplus\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(clf, out_file=dot_data,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True,feature_names = features,class_names=['0','1'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "graph.write_png('Biopsy.png')\n",
        "Image(graph.create_png())"
      ],
      "metadata": {
        "id": "9Udm90RKbxvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Logitic Regression classifer object\n",
        "\n",
        "#Create an initial Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=100)\n",
        "\n",
        "# Complete the code to train Logistic Regression Classifer with the traning dataset \n",
        "logreg = logreg.fit(X_train, y_train)\n",
        "\n",
        "#Complete the code to make predictions for the test dataset\n",
        "y_pred = logreg.predict(X_test)\n"
      ],
      "metadata": {
        "id": "HbR08Ygw_cSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print confusion matrix and evaluation report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "XLa2Dp19_sPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Oja-lMxGuu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oip5td4kGxO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Telco Churn**\n"
      ],
      "metadata": {
        "id": "xcSoSjFeI6kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load necessary libraries here\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from sklearn.metrics import precision_recall_curve, confusion_matrix, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for model evaluation"
      ],
      "metadata": {
        "id": "RkAnAyf8wpOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dataset"
      ],
      "metadata": {
        "id": "JyiY1CzHxcHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data using pandas.read_csv(filepath_or_url, sep=',')\n",
        "url = 'https://raw.githubusercontent.com/thuc-github/MIS710-T12023/main/Week%204/WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
        "\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "0_ThSWV7ws1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA\n",
        "\n",
        "* How many rows and columns in the dataset? \n",
        "* Return the first n rows.\n",
        "* What are the columns and their datatypes?\n",
        "* Is there any missing values? \n",
        "* Any strong correlation from the dataset?  \n",
        "* How to deal with categorical features? \n",
        "\n"
      ],
      "metadata": {
        "id": "hTe1NMnwx6eD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Exploration\n",
        "* Demographics (age, gender, partner and dependent status)\n",
        "* Customer account information (Tenures, contracts)\n",
        "* Distribution of services \n",
        "* Relation between variables \n",
        "* Distribution of predictor variable (`Churn`)"
      ],
      "metadata": {
        "id": "FfOo1H8i0QD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation \n",
        "\n",
        "\n",
        "1.   Prepare X, y\n",
        "2.   Prepare X_train, X_test, y_train, y_test (hint: using `train_test_split')\n",
        "\n"
      ],
      "metadata": {
        "id": "KmoCcKvKyOHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model implementation\n",
        "\n",
        "1. Try with the original data. What's the performance?\n",
        "2. Let's add data normalisation. Has the performance been improved?"
      ],
      "metadata": {
        "id": "vtvVRhsy0P29"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_p04O81jE4u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance evaluation\n",
        "* Classification report\n",
        "* Confusion matrix \n",
        "* Importance weight\n",
        "* ROC and AUC"
      ],
      "metadata": {
        "id": "zZbv7b2HzPyy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wccMRctfG4kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qe2xZt_3weE"
      },
      "source": [
        "# Insurance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading libraries"
      ],
      "metadata": {
        "id": "R90z3fZlnfr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import r2_score,mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "RbNZYbzuFxcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dataset"
      ],
      "metadata": {
        "id": "DKgxrqkPFxcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data using pandas.read_csv(filepath_or_url, sep=',')\n",
        "url = 'https://raw.githubusercontent.com/thuc-github/MIS710-T12023/main/Week%203/insurance.csv'\n",
        "\n",
        "df = pd.read_csv(url)\n"
      ],
      "metadata": {
        "id": "dFk3ixy4Fxcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA\n",
        "\n",
        "* How many rows and columns in the dataset? \n",
        "* Return the first n rows.\n",
        "* What are the columns and their datatypes?\n",
        "* Is there any missing values? \n",
        "* How to deal with categorical features? \n",
        "* Any strong correlation from the dataset?  \n",
        "* What are the stats for the `charges`? Plot overall distribution of `charges`; and ditribution of chareges for smoker and non-smokers. Practice more with `bmi`, `age` and `sex` variables. \n",
        "\n"
      ],
      "metadata": {
        "id": "pESrZ5KkHvux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many rows and columns in the dataset?\n",
        "df\n",
        "\n",
        "# Return the first n rows.\n",
        "df.head()\n",
        "\n",
        "# What are the columns and their datatypes?\n",
        "df.info()\n",
        "\n",
        "# Is there any missing values?\n",
        "df.isnull().sum()\n",
        "\n",
        "# Any strong correlation from the dataset?\n",
        "df.corr()"
      ],
      "metadata": {
        "id": "716hxouZV81v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation plot\n",
        "f, ax = plt.subplots(figsize=(10, 8))\n",
        "corr = df.corr()\n",
        "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(240,10,as_cmap=True),\n",
        "            square=True, ax=ax)"
      ],
      "metadata": {
        "id": "0N8FHWVPAICT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How to deal with categorical features?\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#sex\n",
        "le = LabelEncoder()\n",
        "le.fit(df.sex.drop_duplicates()) \n",
        "df.sex = le.transform(df.sex)\n",
        "# smoker or not\n",
        "le.fit(df.smoker.drop_duplicates()) \n",
        "df.smoker = le.transform(df.smoker)\n",
        "#region\n",
        "le.fit(df.region.drop_duplicates()) \n",
        "df.region = le.transform(df.region)\n"
      ],
      "metadata": {
        "id": "mn-qiebgHvuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' \n",
        "What are the stats for the charges? Plot overall distribution of charges; \n",
        "and ditribution of chareges for smoker and non-smokers. \n",
        "'''\n",
        "df.charges.describe()"
      ],
      "metadata": {
        "id": "ifzyfkCzWgEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.charges.hist(bins=50, figsize=(12,8))"
      ],
      "metadata": {
        "id": "fcS7URxjWrM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.charges.hist(by=df.smoker, bins=50, figsize=(12,8))"
      ],
      "metadata": {
        "id": "DhnsWD_sWz26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative using seaborn\n",
        "\n",
        "f= plt.figure(figsize=(12,5))\n",
        "\n",
        "ax=f.add_subplot(121)\n",
        "sns.distplot(df[(df.smoker == 1)][\"charges\"],color='c',ax=ax)\n",
        "ax.set_title('Distribution of charges for smokers')\n",
        "\n",
        "ax=f.add_subplot(122, sharex = ax)\n",
        "sns.distplot(df[(df.smoker == 0)]['charges'],color='b',ax=ax)\n",
        "ax.set_title('Distribution of charges for non-smokers')"
      ],
      "metadata": {
        "id": "85DCFc2uBsRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation \n",
        "\n",
        "\n",
        "1.   Prepare X, y\n",
        "2.   Prepare X_train, X_test, y_train, y_test (hint: using `train_test_split')\n",
        "\n"
      ],
      "metadata": {
        "id": "px8Kp6KuHvu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['charges'], axis = 1)\n",
        "y = df.charges\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "uinx0DLAHvu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model implementation\n",
        "\n",
        "1. Try with the original data. What's the performance?\n",
        "2. Let's add data normalisation. Has the performance been improved?"
      ],
      "metadata": {
        "id": "YQNdgx1nHvu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression().fit(X_train,y_train)\n",
        "\n",
        "y_train_pred = lr.predict(X_train)\n",
        "y_test_pred = lr.predict(X_test)\n",
        "\n",
        "print('MSE_Train: {}, MSE_Test: {}, MAE_Train: {}, MAE_Test: {}'.format(mean_squared_error(y_train, y_train_pred),\n",
        "                                                      mean_squared_error(y_test, y_test_pred),\n",
        "                                                      mean_absolute_error(y_train, y_train_pred),\n",
        "                                                      mean_absolute_error(y_test, y_test_pred)))\n",
        "\n",
        "print('R2 train data: %.3f, R2 test data: %.3f' % (\n",
        "r2_score(y_train,y_train_pred),\n",
        "r2_score(y_test,y_test_pred)))"
      ],
      "metadata": {
        "id": "rclQ0qPI2rq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "lr = DecisionTreeRegressor(criterion='friedman_mse', max_depth=5, max_leaf_nodes=10, min_samples_leaf=2, min_samples_split=2).fit(X_train,y_train)\n",
        "\n",
        "y_train_pred = lr.predict(X_train)\n",
        "y_test_pred = lr.predict(X_test)\n",
        "\n",
        "print('MSE_Train: {}, MSE_Test: {}, MAE_Train: {}, MAE_Test: {}'.format(mean_squared_error(y_train, y_train_pred),\n",
        "                                                      mean_squared_error(y_test, y_test_pred),\n",
        "                                                      mean_absolute_error(y_train, y_train_pred),\n",
        "                                                      mean_absolute_error(y_test, y_test_pred)))\n",
        "\n",
        "print('R2 train data: %.3f, R2 test data: %.3f' % (\n",
        "r2_score(y_train,y_train_pred),\n",
        "r2_score(y_test,y_test_pred)))"
      ],
      "metadata": {
        "id": "dn3JAcQfIHpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "plt.scatter(y_train_pred, y_train_pred - y_train,\n",
        "          c = 'black', marker = 'o', s = 35, alpha = 0.5,\n",
        "          label = 'Train data')\n",
        "plt.scatter(y_test_pred, y_test_pred - y_test,\n",
        "          c = 'c', marker = 'o', s = 35, alpha = 0.7,\n",
        "          label = 'Test data')\n",
        "plt.xlabel('Predicted values')\n",
        "plt.ylabel('Tailings')\n",
        "plt.legend(loc = 'upper left')\n",
        "plt.hlines(y = 0, xmin = 0, xmax = 60000, lw = 2, color = 'red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2zKC9yW8C2Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **House Price**\n",
        "Let's try another dataset we are familiar with from Week 3"
      ],
      "metadata": {
        "id": "twt3fRE9cjmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading data**"
      ],
      "metadata": {
        "id": "866MsrxHc0N0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "records = pd.read_csv('https://raw.githubusercontent.com/VanLan0/MIS710-ML/main/Datasets/Housing3.csv')\n",
        "\n",
        "#explore the dataset\n",
        "print(records)\n",
        "\n",
        "print('Sample size:', records.shape[0])\n",
        "print('Number of columns:', records.shape[1]) "
      ],
      "metadata": {
        "id": "4BGs5uFHc2v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Inspecting and handling missing data and incorrectly recorded data**"
      ],
      "metadata": {
        "id": "m21qy24EefS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#write code to display the following"
      ],
      "metadata": {
        "id": "lA-2hwgPdYu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#area is wrongly documented as string\n",
        "records['area'] = records['area'].apply(pd.to_numeric, errors='coerce')"
      ],
      "metadata": {
        "id": "ph2ZHFyVeaVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#write code to inspect missing data"
      ],
      "metadata": {
        "id": "wK390-v8din0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fill in missing numerical data with mean and categorical data with mode\n",
        "records['area'].fillna(records['area'].mean(),inplace=True)\n",
        "records['furnishingstatus'].fillna(records['furnishingstatus'].mode()[0], inplace=True) #there can be more than one mode\n",
        "\n",
        "#handle missing mainroad data"
      ],
      "metadata": {
        "id": "a_gjjM-Ids12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Last week, we learned to convert categorical variables to numerical using LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()"
      ],
      "metadata": {
        "id": "goCycrlZe2-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for example:\n",
        "records['mainroad_N'] = encoder.fit_transform(records['mainroad', 'basement',)\n",
        "records['basement_N'] = encoder.fit_transform(records['basement'])\n",
        "\n",
        "#encode other variables as needed"
      ],
      "metadata": {
        "id": "H-rOWHiJe-gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exploratory data analysis**"
      ],
      "metadata": {
        "id": "6pbB2p5Eept1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#explore data yourself\n",
        "\n",
        "#for example, generate dendrograms to show hierarchical clustering  \n",
        "sns.clustermap(records.corr(), square=True, cmap='Blues', annot=True, row_cluster=False)"
      ],
      "metadata": {
        "id": "1Hau_sxneu8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Selection Features and Label**\n",
        "Select predictors (attributes) for Classification Set role (Target)"
      ],
      "metadata": {
        "id": "7ZdyhCpBjja6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Select predictors\n",
        "#features=['area','bedrooms', ....]\n",
        "X=records[features]\n"
      ],
      "metadata": {
        "id": "2EEWzSCojDEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#specify the label\n",
        "y=records['price']\n",
        "y.head()"
      ],
      "metadata": {
        "id": "5Uhx057Oj38U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Splitting the Dataset**\n",
        "Split arrays or matrices into random train and test subsets https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn.model_selection.train_test_split"
      ],
      "metadata": {
        "id": "fpiNENtuj83l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "\n",
        "# Split dataset into training set 70% and test set 30%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)  # 70% training and 30% testing \n",
        "\n",
        "#inspect the split datasets\n",
        "print(X_train.head())\n",
        "print(y_train.head())\n",
        "\n",
        "print('Training dataset size:',X_train.shape)\n",
        "print('Test dataset size:',X_test.shape)\n"
      ],
      "metadata": {
        "id": "5fetOCHzj8of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training a Decision Tree Regressor**\n",
        "Train a model using the training dataset Make prediction using the model for the test dataset Read about DecisionTreeRegressor at: \n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor"
      ],
      "metadata": {
        "id": "_lQffPa-kT1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import DecisionTreeRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "#instantiate a decision tree regressor and fit it with the training data\n",
        "regressor = DecisionTreeRegressor(max_depth=20, max_leaf_nodes=15, random_state=1)\n",
        "\n",
        "#write code to train the regressor\n",
        "\n"
      ],
      "metadata": {
        "id": "aYNzAQ3Gkk6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Applying the Decision Tree Regressor on the testset**"
      ],
      "metadata": {
        "id": "BR-HyIfjkwWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#predict prices\n",
        "\n"
      ],
      "metadata": {
        "id": "JxPbaKMAkrr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating the model performance**\n"
      ],
      "metadata": {
        "id": "sd2QGPfVk9kV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model\n",
        "from sklearn import metrics\n",
        "print('Mean Absolute Error:', '%.0f' % metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('Mean Squared Error:', '%.0f' % metrics.mean_squared_error(y_test, y_pred))\n",
        "print('Root Mean Squared Error:', '%.0f' %np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "metadata": {
        "id": "JTh_z8BBlAo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.float_format', lambda x: '%.0f' % x)\n",
        "records['price'].describe()"
      ],
      "metadata": {
        "id": "FVmv00MBlvdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment on the errors in relation to the price stats"
      ],
      "metadata": {
        "id": "Kw38hbFDGTuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.externals.six import StringIO \n",
        "from IPython.display import Image \n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "dot_data = StringIO()\n",
        "export_graphviz(regressor, out_file=dot_data, \n",
        "filled=True, rounded=True,\n",
        "special_characters=True, feature_names = features,class_names=['0','1'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
        "graph.write_png('HousePricePrediction.png')\n",
        "Image(graph.create_png())\n"
      ],
      "metadata": {
        "id": "etW4EmPYlGWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dg6SpbV2FwNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jRzvgRjIGLja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Congratulations**\n",
        "You now can try another dataset on your own: https://www.kaggle.com/datasets/ahmettyilmazz/fuel-consumption"
      ],
      "metadata": {
        "id": "PLYakWmiDOye"
      }
    }
  ]
}