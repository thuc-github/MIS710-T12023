{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thuc-github/MIS710-T12023/blob/main/Week%206/MIS710_Lab6_KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNkJtLWoPpW7"
      },
      "source": [
        "\n",
        "# **MIS710 Lab 6 Week 6**\n",
        "Author: Associate Professor Lemai Nguyen\n",
        "\n",
        "Objectives: \n",
        "1. To learn to build and test KNN models for classification and regression\n",
        "2. To evaluate the models based on the ML problem\n",
        "3. To optimise k\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Import libraries and functions**"
      ],
      "metadata": {
        "id": "SSX6_DT9CA72"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVf5buwkml_I"
      },
      "source": [
        "# import libraries \n",
        "import pandas as pd #for data manipulation and analysis\n",
        "import numpy as np\n",
        " \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydotplus #interface for graph visualisation\n",
        "!pip install graphviz #for graph visualisation"
      ],
      "metadata": {
        "id": "jr2L4ryAe3hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B38Q50gZm1vQ"
      },
      "source": [
        "# **2. Case One: Churn Prediction**\n",
        "\n",
        "**KNN classifier**\n",
        "\n",
        "Dataset: [Telco Customer Churn] https://www.kaggle.com/datasets/blastchar/telco-customer-churn\n",
        "\n",
        "**Context**\n",
        "\"Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.\" [IBM Sample Data Sets]\n",
        "\n",
        "**Content**\n",
        "Each row represents a customer, each column contains customer’s attributes described on the column Metadata.\n",
        "\n",
        "The data set includes information about:\n",
        "\n",
        "* Customers who left within the last month – the column is called Churn\n",
        "Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n",
        "* Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n",
        "* Demographic info about customers – gender, age range, and if they have partners and dependents\n",
        "\n",
        "**Inspiration**\n",
        "To explore this type of models and learn more about the subject.\n",
        "\n",
        "New version from IBM:\n",
        "https://community.ibm.com/community/user/businessanalytics/blogs/steven-macko/2019/07/11/telco-customer-churn-1113"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.1. Loading data**"
      ],
      "metadata": {
        "id": "xPWgO9M_mgUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url='https://raw.githubusercontent.com/VanLan0/MIS710/main/Customers.csv'"
      ],
      "metadata": {
        "id": "GFufK8zW-RQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX5VNkrqm3Rg"
      },
      "source": [
        "#loading data\n",
        "records = pd.read_csv(url)\n",
        "\n",
        "records.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.2. Data Preparation, Exploration and Visualisation**"
      ],
      "metadata": {
        "id": "rm39-72_2FHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data cleansing**\n",
        "\n",
        "* Inspect columns and correct data types\n",
        "* Detecting and handling missing data\n"
      ],
      "metadata": {
        "id": "iVidcigwCK-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect columns and data types to print the following outcome\n"
      ],
      "metadata": {
        "id": "7AveK5ALkjy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#totalcharges is wrongly documented as string\n",
        "records['TotalCharges'] = records['TotalCharges'].apply(pd.to_numeric, errors='coerce')"
      ],
      "metadata": {
        "id": "5InkiYMeEBhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect missing data, hint .isnull().sum())\n"
      ],
      "metadata": {
        "id": "ygrRVlGB_l7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#As the distribution is skewed, replace the missing values with median\n",
        "records['TotalCharges'].fillna(records['TotalCharges'].median(),inplace=True)\n"
      ],
      "metadata": {
        "id": "xxFmkZ4uSKms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question.** Alternatively you can drop the datapoints with missing Total Charges, why and why not?\n",
        "\n",
        "records.dropna(subset=['TotalCharges'], axis = 0, inplace = True)"
      ],
      "metadata": {
        "id": "hduHVn20lNmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove customer IDs from the data set, hint .drop(['customerID'], axis = 1)\n"
      ],
      "metadata": {
        "id": "PGaQ69ZnmGoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **EDA**\n",
        "\n",
        "* Analyse and visualise each variable\n",
        "* Any strong correlation from the dataset?  \n",
        "* How to deal with categorical features? "
      ],
      "metadata": {
        "id": "3R1K8K0YCPpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect target variable\n",
        "records.Churn.value_counts()"
      ],
      "metadata": {
        "id": "byg_Efd3AbR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=records['Churn'])"
      ],
      "metadata": {
        "id": "JOPVzWvA7veC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cats=['gender','SeniorCitizen', 'Dependents', 'PhoneService','MultipleLines','InternetService','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies','Contract','PaperlessBilling','PaymentMethod']\n",
        "for i in cats:\n",
        "   print(i, ':\\n')\n",
        "   print(records[i].value_counts())\n",
        "   print('\\n')\n",
        "   "
      ],
      "metadata": {
        "id": "x7TD7lvcZvcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in cats:\n",
        "   plt.figure()\n",
        "   sns.countplot(x=records[i])"
      ],
      "metadata": {
        "id": "4olQJKcvZDxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write your own observations"
      ],
      "metadata": {
        "id": "RkQ37r3oK0uZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nums=['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "for i in nums:\n",
        "   print(i, ':\\n')\n",
        "   print(records[i].describe())\n",
        "   print('\\n')\n"
      ],
      "metadata": {
        "id": "m7wpxUvlAyl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in nums:\n",
        "  plt.figure()\n",
        "  #write your own code to display boxplot for (x=records[i])\n"
      ],
      "metadata": {
        "id": "R5fRaTuwbjkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in nums:\n",
        "  plt.figure()    \n",
        "  #write your owncode to display histplot(data=records, x=i,  bins=20, kde=True)\n"
      ],
      "metadata": {
        "id": "VHf1N8EACotn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore relationships"
      ],
      "metadata": {
        "id": "ukcGozxN09SI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in cats:\n",
        "   plt.figure()\n",
        "   sns.countplot(x=records[i], hue=records['Churn'])"
      ],
      "metadata": {
        "id": "6ViaDaUX1ybv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in nums:\n",
        "  plt.figure()    \n",
        "  sns.kdeplot(data=records, x=i, hue='Churn')"
      ],
      "metadata": {
        "id": "bN-5Rkkh1ADe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.clustermap(data=records.corr(), annot=True, cmap='crest')"
      ],
      "metadata": {
        "id": "uez-latNYJNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwWOEh8enmXM"
      },
      "source": [
        "### **Data preparation**\n",
        "* Feature selection\n",
        "* Target specification\n",
        "* Data spliting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the categorical columns\n",
        "cat_columns = records.select_dtypes(include=['object']).columns\n",
        "cat_columns"
      ],
      "metadata": {
        "id": "aGc0JZTGKwDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert categorical variables to numerical using get dummies\n",
        "records=pd.get_dummies(records, columns=cat_columns, drop_first=True)\n",
        "\n",
        "print(records.info())"
      ],
      "metadata": {
        "id": "I5xnrTLFLut2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records=records.rename(columns={'Churn_Yes':'Churn'})"
      ],
      "metadata": {
        "id": "5kCqALZUZjUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#write your own code to display a heatmap for data=records.corr(), cmap=\"Blues\""
      ],
      "metadata": {
        "id": "J51EWAlr-Wqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define predictors and label\n",
        "X=records.drop('Churn', axis=1)\n",
        "y=records['Churn']\n"
      ],
      "metadata": {
        "id": "wwwbHnZuPAcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.3. KNN Classifier Model building**"
      ],
      "metadata": {
        "id": "Aac7copVCjqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier #Import KNN classifier class\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "FSW-NExg3i9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import scaler\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "B4UODmurPlNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is a common practice not to scale the target variable (y_train and y_test) because it is not used as an input to the model during training or prediction.\n",
        "\n",
        "Algorithms such as decision tree regressors, random forests, and support vector regression are generally not very sensitive to differences in scale between the input variables and target variable. \n",
        "\n",
        "However, algorithms such as linear regression and neural networks can be more sensitive to scale differences and may require normalization or standardization of the input variables and/or target variable.\n",
        "\n",
        "If you scale the target variable (y_train and y_test), you would need to perform an inverse transformation on the predicted values to get them back to their original scale."
      ],
      "metadata": {
        "id": "rgDx8Lk72I_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_norm=scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "k76aV7tbBRX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into X_train, X_test, y_train, y_test hint: use train_test_split(X_norm, y, test_size=0.35, stratify = y, random_state=2023 )\n"
      ],
      "metadata": {
        "id": "R8Q9iW0KGXMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.4. Performance Evaluation**\n",
        "* Classification report\n",
        "* Confusion matrix \n",
        "* ROC and AUC"
      ],
      "metadata": {
        "id": "0NeRgk3mC3dR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Coym-ehdnoTy"
      },
      "source": [
        "# Train a KNN model\n",
        "k = 15 # Number of neighbors\n",
        "knn = KNeighborsClassifier(n_neighbors=k) #try it with p=1 and p=2\n",
        "\n",
        "#fit the knn with X_train and y_train\n",
        "\n",
        "# Make predictions on the testing set\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Classification report**"
      ],
      "metadata": {
        "id": "KVJdXlV9lrH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the confusion_matrix and classification report using y_test and y_pred\n"
      ],
      "metadata": {
        "id": "5bAhGHnshED-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get predicted probabilities for the main class\n",
        "y_pred_probs_norm = knn.predict_proba(X_test)\n",
        "y_pred_probs_norm = y_pred_probs_norm[:, 1]\n",
        "print(y_pred_probs_norm)"
      ],
      "metadata": {
        "id": "TMOSqL0QB9C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ROC curve and AUC**"
      ],
      "metadata": {
        "id": "0AuSfxYBlyNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get fpr and tpr and plot the ROC curve\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs_norm)\n",
        "print('AUC:', '%.3f' % metrics.auc(fpr, tpr))\n",
        "sns.scatterplot(x=fpr, y=tpr, label='Roc Curve')"
      ],
      "metadata": {
        "id": "JKkIH-q5DK01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdvcTDo8txLT"
      },
      "source": [
        "inspection=pd.DataFrame({'Actual':y_test, 'Predicted':y_pred, 'Probability':y_pred_probs_norm})\n",
        "inspection.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Find the best threshold**\n",
        "Find the best threshold using the thresholds in ROC curve\n",
        "\n",
        "Examine the two blocks of code below, which one would you like to use, when and why?"
      ],
      "metadata": {
        "id": "LPzsy1lueSwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# Find the best threshold based on accuracy\n",
        "accuracy = []\n",
        "for threshold in thresholds:\n",
        "    y_pred_t = [1 if prob >= threshold else 0 for prob in y_pred_probs_norm]\n",
        "    accuracy.append(accuracy_score(y_test, y_pred_t))\n",
        "best_threshold = thresholds[accuracy.index(max(accuracy))]\n",
        "\n",
        "print(best_threshold)"
      ],
      "metadata": {
        "id": "qMetj-_neLYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "# Find the best threshold based on F1 score\n",
        "f1 = []\n",
        "for threshold in thresholds:\n",
        "    y_pred_t = [1 if prob >= threshold else 0 for prob in y_pred_probs_norm]\n",
        "    f1.append(f1_score(y_test, y_pred_t))\n",
        "best_threshold = thresholds[f1.index(max(f1))]\n",
        "\n",
        "print(best_threshold)"
      ],
      "metadata": {
        "id": "GpvUs4SWkIzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get predicted probabilities for best threshold\n",
        "y_pred_best = (y_pred_probs_norm >= best_threshold).astype(bool)\n",
        "\n",
        "print(y_pred_best)\n",
        " \n",
        " "
      ],
      "metadata": {
        "id": "VCSorptQnLCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print confusion matrix\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred_best))\n",
        "print(classification_report(y_test, y_pred_best))"
      ],
      "metadata": {
        "id": "pA5gZECJqOf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#what is displayed in the outcomes?\n",
        "RocCurveDisplay.from_predictions(y_test, y_pred_probs_norm)\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_best)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MDnUxAV4VoOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W00EmgDn0Ue"
      },
      "source": [
        "#Model evaluation with the original predictions \n",
        "print(\"Accuracy: \", '%.3f' % metrics.accuracy_score(y_test,y_pred))\n",
        "print(\"Precision: \", '%.3f' % metrics.precision_score(y_test,y_pred))\n",
        "print(\"Recall: \", '%.3f' % metrics.recall_score(y_test,y_pred))\n",
        "print(\"F1: \", '%.3f' % metrics.f1_score(y_test,y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now that we have the y_pred_best for the best threshold, generate the above evaluation results for it \n",
        "\n"
      ],
      "metadata": {
        "id": "rE4qFrp9r14J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.5. Optimising k**\n",
        "based on accuracy"
      ],
      "metadata": {
        "id": "arZvU7US3nUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of k values to test\n",
        "k_values = list(range(1, 41))\n",
        "\n",
        "# Train and evaluate KNN classifiers with different k values\n",
        "\n",
        "best_k=0\n",
        "best_accuracy=0\n",
        "best_f1=0\n",
        "accuracy_scores = []\n",
        "accuracy = 0\n",
        "error_rate=1-accuracy\n",
        "error_rates=[]\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred_k=knn.predict(X_test)\n",
        "    accuracy = knn.score(X_test, y_test)\n",
        "    accuracy_scores.append(accuracy)\n",
        "    error_rates.append(1-accuracy)\n",
        "    if accuracy > best_accuracy:\n",
        "        best_k = k\n",
        "        best_accuracy = accuracy\n",
        "        best_f1 = metrics.f1_score(y_test, y_pred_k)\n",
        "\n",
        "# Find the best k value with highest accuracy score\n",
        "#best_k = k_values[np.argmax(accuracy_scores)]\n",
        "print(f\"Best k value: {best_k}\")\n",
        "print(f\"Best accuracy: {best_accuracy:.3f}\")\n",
        "print(f\"F1 score for best accuracy: {best_f1:.3f}\")\n",
        "\n",
        "# Plot k values against accuracy scores\n",
        "#plt.plot(k_values, accuracy_scores, color='red')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Error rate')\n",
        "plt.title('Error rates for different k values')\n",
        "plt.plot(k_values, error_rates, color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6bmR785J6bvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimise k based on f1_score**"
      ],
      "metadata": {
        "id": "sRxY3z7aDMfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of k values to test\n",
        "k_values = list(range(1, 41))\n",
        "\n",
        "# Train and evaluate KNN classifiers with different k values\n",
        "best_k=0\n",
        "best_f1=0\n",
        "best_accuracy=0\n",
        "f1_scores = []\n",
        "f1 = 0\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred_k=knn.predict(X_test)\n",
        "    f1 = metrics.f1_score(y_test, y_pred_k)\n",
        "    f1_scores.append(f1)\n",
        "    accuracy_k=metrics.accuracy_score(y_test, y_pred_k)\n",
        "    if ((f1 > best_f1) ):\n",
        "        best_k = k\n",
        "        best_f1 = f1\n",
        "        best_accuracy = metrics.accuracy_score(y_test,y_pred_k)\n",
        "\n",
        "# Find the best k value with highest f1 score\n",
        "#best_k = k_values[np.argmax(accuracy_scores)]\n",
        "print(f\"Best k value: {best_k}\")\n",
        "print(f\"Best F1 score: {best_f1:.3f}\")\n",
        "print(f\"Accuracy for Best F1 score: {best_accuracy:.3f}\")\n",
        "\n",
        "# Plot k values against accuracy scores\n",
        "#plt.plot(k_values, accuracy_scores, color='red')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('F1 score')\n",
        "plt.title('F1 scores for different k values')\n",
        "plt.plot(k_values, f1_scores, color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xPpX3EfSDR3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try it yourself!**\n",
        "\n",
        "* Rebuild the model with the optimal k\n",
        "* Evaluate the model"
      ],
      "metadata": {
        "id": "bSk2aPgy4zj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Insight: KNNImputer**\n",
        "\n",
        "KNNImputer looks at the K nearest neighboring data points that have complete information for a variable with missing and takes an average (or median) of those values to fill in the missing value. The value of K is specified by the user as a hyperparameter.\n",
        "\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "**Impute missing data using KNN imputation**\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "records[['TotalCharges_imputed']] = imputer.fit_transform(records[['TotalCharges']])\n",
        "\n",
        "**Try it the above code yourself**\n",
        "\n",
        "Note: KNNImputer cannot be directly applied to categorical data. "
      ],
      "metadata": {
        "id": "w3VJ8_5_IURz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Case Two: Insurance Premium Estimation**\n",
        "\n",
        "**KNN regression**\n",
        "\n",
        "https://www.kaggle.com/datasets/mirichoi0218/insurance \n",
        "\n",
        "**Context**\n",
        "Machine Learning with R by Brett Lantz is a book that provides an introduction to machine learning using R. As far as I can tell, Packt Publishing does not make its datasets available online unless you buy the book and create a user account which can be a problem if you are checking the book out from the library or borrowing the book from a friend. All of these datasets are in the public domain but simply needed some cleaning up and recoding to match the format in the book.\n",
        "\n",
        "Content - Columns\n",
        "\n",
        "* age: age of primary beneficiary\n",
        "\n",
        "* sex: insurance contractor gender, female, male\n",
        "\n",
        "* bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n",
        "objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
        "\n",
        "* children: Number of children covered by health insurance / Number of dependents\n",
        "\n",
        "* smoker: Smoking\n",
        "\n",
        "* region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
        "\n",
        "* charges: Individual medical costs billed by health insurance\n",
        "\n",
        "**Acknowledgements**\n",
        "The dataset is available on GitHub here.\n",
        "\n",
        "**Inspiration**\n",
        "Can you accurately predict insurance costs?"
      ],
      "metadata": {
        "id": "-Mtzwlk8yMEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.1 Loading data**"
      ],
      "metadata": {
        "id": "Yc063HkDoiBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url='https://raw.githubusercontent.com/VanLan0/MIS710/main/insurance.csv'\n"
      ],
      "metadata": {
        "id": "PIc078bDyXax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading data\n",
        "records = pd.read_csv(url)\n",
        "\n",
        "records.head()"
      ],
      "metadata": {
        "id": "hfCN0o38zsIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.2. Data Preparation, Exploration and Visualisation**"
      ],
      "metadata": {
        "id": "YYrI_8dVpF83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data cleansing**\n",
        "\n",
        "* Inspect columns and correct data types\n",
        "* Detecting and handling missing data\n"
      ],
      "metadata": {
        "id": "s0TrAbgVpMg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "records.info()"
      ],
      "metadata": {
        "id": "pvZMZ09Sz2y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect missing data\n",
        "print(records.isnull().sum())"
      ],
      "metadata": {
        "id": "xdlVQ6kezuYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **EDA**\n",
        "\n",
        "* Analyse and visualise each variable\n",
        "* Any strong correlation from the dataset?  \n",
        "* How to deal with categorical features? "
      ],
      "metadata": {
        "id": "PR_O3ulco8-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "records.describe()"
      ],
      "metadata": {
        "id": "h2SJMBpc4LI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nums=['age','bmi', 'dependants', 'charges']\n",
        "for i in nums:\n",
        "  plt.figure()\n",
        "  #write code to display kdeplot(data=records, x=i)"
      ],
      "metadata": {
        "id": "8UQ0NPZzqauZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in nums:\n",
        "  plt.figure()\n",
        "  #write code to display displot for each numerical variable (data=records, x=i, bins=20)"
      ],
      "metadata": {
        "id": "wcGjxnV4rVuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cats=['sex','smoker', 'region', 'dependants']\n",
        "for i in cats:\n",
        "   print(i, ':\\n')\n",
        "   print(records[i].value_counts())\n",
        "   print('\\n')"
      ],
      "metadata": {
        "id": "AMQcbWGgpqUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in cats:\n",
        "   print(i, ':\\n')\n",
        "   plt.figure()\n",
        "   sns.countplot(data=records, x=i)"
      ],
      "metadata": {
        "id": "ni0lbX2qpyHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write your observations of the following graphs"
      ],
      "metadata": {
        "id": "v4-Dt9JPNdpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.kdeplot(data=records, x='age', hue='region')"
      ],
      "metadata": {
        "id": "ZmLE879Ez_ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.kdeplot(data=records, x='charges', hue='region')"
      ],
      "metadata": {
        "id": "2ch0qiIB0nC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your own code to generate the graph below"
      ],
      "metadata": {
        "id": "rBEByXIUC-MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(data=records, x='age', y='charges', hue='smoker')"
      ],
      "metadata": {
        "id": "b41t4xxE0pDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#write your own code to display the below"
      ],
      "metadata": {
        "id": "yRk3TKMv5fhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task:** Write your observation for the graph below:"
      ],
      "metadata": {
        "id": "dQODEeDJN41a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(data=records, x='charges', y='smoker', showmeans=True)"
      ],
      "metadata": {
        "id": "FqOT4dH50UI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#write your owncode to display the following"
      ],
      "metadata": {
        "id": "nr_kF05QEjoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kP0Iqlj4DgDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualise clustermap\n",
        "sns.clustermap(data=records.corr(), cmap=\"Blues\",linewidths=.9, annot=True)"
      ],
      "metadata": {
        "id": "vV7WCkjTEvcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert categorical variables to numerical using get dummies\n",
        "records=pd.get_dummies(records, columns=['sex', 'region'], drop_first=True)\n",
        "\n",
        "print(records.info())"
      ],
      "metadata": {
        "id": "6AQyeAYj1JEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert categorical data to numerical \n",
        "def coding_smoking(x):\n",
        "    if x=='yes': return 1\n",
        "    if x=='no': return 0\n",
        "       \n",
        "records['smoker'] = records['smoker'].apply(coding_smoking)"
      ],
      "metadata": {
        "id": "Gcyroz80uJw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records.info()"
      ],
      "metadata": {
        "id": "p9ITslM51jAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data preparation**\n",
        "\n",
        "* Feature selection: X\n",
        "* Target specification: y\n",
        "* Scale data\n",
        "* Data spliting: X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "Td3485YPu6K_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=records.drop('charges', axis=1)\n",
        "y=records['charges']"
      ],
      "metadata": {
        "id": "KGcLY9Sw1nQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't often scale the target variable (y_train and y_test) in regression problems because it is not used as an input to the model during training or prediction. If models are sensitive to scale (eg linear regression) then it is good to scale y as well."
      ],
      "metadata": {
        "id": "ZOUrecv8vQGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_norm=scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "hLcDOrsr14uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3)"
      ],
      "metadata": {
        "id": "Cvan1TF22PQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.3. KNN Model building**"
      ],
      "metadata": {
        "id": "CSvN-EB9wSXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n"
      ],
      "metadata": {
        "id": "iJ4VvBmu2HVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a KNN regressor object\n",
        "k=5\n",
        "knn = KNeighborsRegressor(k)\n",
        "\n",
        "# Fit the model to the training data\n",
        "\n"
      ],
      "metadata": {
        "id": "YRlnPPjC2cik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.4. Performance Evaluation**\n",
        "* Root Mean Squared Error (RMSE)measures the differences between predicted and actual values of the target variable. \n",
        "\n",
        "* Mean Absolute Error (MAE) measures the average magnitude of the errors between predicted and actual values.\n",
        "\n",
        "* R-Squared (R²) measures the proportion of variance in the target variable that can be explained by the independent variables - also called Coefficient of Determination. "
      ],
      "metadata": {
        "id": "SBjrI-J7we3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the house prices for the testing data\n",
        "y_pred = knn.predict(X_test)"
      ],
      "metadata": {
        "id": "7yREa2Pg3Bks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inspection=pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})\n",
        "inspection.head()"
      ],
      "metadata": {
        "id": "zOczlGkW20_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate performance metrics\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Print performance metrics\n",
        "print(\"Root Mean Squared Error: {:.3f}\".format(rmse))\n",
        "print(\"R Squared: {:.3f}\".format(r2))\n",
        "print(\"Absolute Squared Error: {:.3f}\".format(mae))"
      ],
      "metadata": {
        "id": "z8PdmKRt2ljI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Write code to review descriptive stars for the target charges"
      ],
      "metadata": {
        "id": "0_WBIIcayeCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task:** Write your own interpretation of the model performance"
      ],
      "metadata": {
        "id": "b3bONrXIO_4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot residuals, i.e. the differences between the actual and predicted values. \n",
        "plt.hist(x=y_test-y_pred, bins=50)\n",
        "plt.xlabel='error'\n",
        "plt.ylabels='count'\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5AFl_56F_bzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if plt.xlabel() plays up, you can reload plt \n",
        "import matplotlib.pyplot as plt\n",
        "from importlib import reload\n",
        "plt=reload(plt)"
      ],
      "metadata": {
        "id": "-4LAZPqB2z1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.kdeplot(x=y_test-y_pred)"
      ],
      "metadata": {
        "id": "0cpYKP_7A4uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a scatter plot of residuals against predicted values\n",
        "plt.scatter(y_pred, y_test-y_pred)\n",
        "plt.title('Residual Plot')\n",
        "plt.ylabel('Residuals')\n",
        "plt.xlabel('Predicted values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "An9cHVwI0L47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.5. Optimising k**\n",
        "based on rmse"
      ],
      "metadata": {
        "id": "7cHI5lxg1bn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of k values to test\n",
        "k_values = list(range(1, 31))\n",
        "\n",
        "# Train and evaluate KNN classifiers with different k values\n",
        "best_k=32\n",
        "best_rmse=30000000\n",
        "error_rates=[]\n",
        "for k in k_values:\n",
        "    knn = KNeighborsRegressor(k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred=knn.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    error_rates.append(rmse)\n",
        "    if rmse <= best_rmse:\n",
        "        best_k = k\n",
        "        best_rmse = rmse\n",
        "\n",
        "# Find the best k value with highest accuracy score\n",
        "print(f\"Best k value: {best_k}\")\n",
        "print(f\"Best rmse: {best_rmse:.3f}\")\n"
      ],
      "metadata": {
        "id": "L4_2PwBNGpd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot k values against accuracy scores\n",
        "plt.ylabel('RMSE')\n",
        "plt.xlabel('k')\n",
        "plt.title('Error rates for different k values')\n",
        "plt.plot(k_values, error_rates, color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qesLpNOJIFIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task:** Write your code to optimise k based on another metric"
      ],
      "metadata": {
        "id": "Ljq318b9PefM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try it yourself!**\n",
        "\n",
        "* Rebuild the model with the optimal k\n",
        "* Evaluate the model"
      ],
      "metadata": {
        "id": "KaOZNA9Y5NR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Do it yourself**\n",
        "\n",
        "Now practise what you have learned in this topic with previous datasets that you are familiar with, such as the Titanic, Biopsy and House Price datasets\n"
      ],
      "metadata": {
        "id": "jJeVsn8m5dDW"
      }
    }
  ]
}